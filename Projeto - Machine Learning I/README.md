# [Detec√ß√£o de fraude em transa√ß√µes de cart√µes de cr√©dito utilizando modelos classificat√≥rios de Machine Learning](https://github.com/grmirand4/sc2023-deteccao-fraude-machine-learning)

**Projeto - Machine Learning I**

Instrutor: [Carlos Stefano](https://www.linkedin.com/in/carlos-stefano/)

**Equipe: [Gabriel Miranda](https://www.linkedin.com/in/grmiranda/), [Marcus Thadeu](https://www.linkedin.com/in/marcus-thadeu/), [Ruann Campos](https://www.linkedin.com/in/ruann-campos/) e [Thiago Caveglion](https://www.linkedin.com/in/thiago-caveglion/)**

## üéØ Objetivo geral
Prever transa√ß√µes fraudulentas em cart√µes de cr√©dito atrav√©s da constru√ß√£o de modelos classificat√≥rios de machine learning (KNN, Decision Tree, Random Forest e Gradient Boosting)

## üìù Objetivos espec√≠ficos
No desenvolvimento de nossa an√°lise, buscamos responder √†s seguintes perguntas:
* √â poss√≠vel prever quais das transa√ß√µes realizadas entre 06/2020 e 12/2020 contidas em `fraudTest.csv` s√£o fraudulentas?
* Quais dos modelos classificat√≥rios constru√≠dos apresentaram melhor performance?

## üìä Sobre o data set
Os data sets `fraudTrain.csv` e `fraudTest.csv` utilizados em nossa an√°lise apresentam informa√ß√µes fict√≠cias retiradas [dessa base de dados do Kaggle](https://www.kaggle.com/datasets/kartik2112/fraud-detection). √â um data set simulado de transa√ß√µes de cart√µes de cr√©dito ocorridas entre as datas de 01/01/2019 a 31/12/2020; refere-se aos cart√µes de 1000 clientes diferentes realizando transa√ß√µes a 800 comerciantes distintos. As colunas dos arquivos incluem:
* `trans_date_trans_time`: data e hora da transa√ß√£o
* `cc_num`: n√∫mero do cart√£o de cr√©dito
* `merchant`: nome do comerciante
* `category`: categoria de compra
* `amt`: valor da transa√ß√£o
* `first`: primeiro nome da pessoa
* `last`: √∫ltimo nome da pessoa
* `gender`: g√™nero da pessoa que realizou a transa√ß√£o
* `dob`: data de nascimento da pessoa que realizou a transa√ß√£o
* `job`: profiss√£o da pessoa que realizou a transa√ß√£o
* `street`, `state`, `zip`: endere√ßo da pessoa que realizou a transa√ß√£o
* `city`: cidade da pessoa que realizou a transa√ß√£o
* `city_pop`: popula√ß√£o da cidade da pessoa que realizou a transa√ß√£o
* `lat`: latitude da pessoa que realizou a transa√ß√£o
* `long`: longitude da pessoa que realizou a transa√ß√£o
* `merch_lat`: latitude do comerciante
* `merch_long`: longitude do comerciante
* `trans_num`, `unix_time`: dados da transa√ß√£o
* `is_fraud`: 1 para transa√ß√µes fraudulentas, 0 caso contr√°rio

## üí° Principais conclus√µes
* De forma geral, fomos capazes de utilizar os diferentes modelos de classifica√ß√£o propostos (KNN, Decision Tree, Random Forest e Gradient Boosting) para a predi√ß√£o de fraudes dados os data sets trabalhados.
  
**Sobre o desempenho de cada modelo:**

* √â poss√≠vel que o **KNN** n√£o seja o melhor modelo para este problema (ou que os modelos trabalhados precisem de mais ajustes).
  * O **recall baixo** (`recall = 0.3` e `recall = 0.25`) representa uma preocupa√ß√£o. Em contextos como detec√ß√£o de fraudes, devemos priorizar um recall mais alto, mesmo que isso signifique sacrificar um pouco a precis√£o. Falsos negativos (fraudes n√£o detectadas) podem ter consequ√™ncias mais graves do que falsos positivos.
  * A **baixa precis√£o** dos modelos sugere que ainda h√° espa√ßo para melhorar a capacidade de se evitar falsos positivos.
    
* **Decision Tree:** foi poss√≠vel criar um modelo com cerca de 92% de precis√£o e 72% de recall, totalizando um `f1-score` de cerca de 0.81 com uma curva ROC de 0.96 de √°rea.

* **Random Forest:** com a otimiza√ß√£o dos hiperpar√¢metros, o modelo atingiu uma acur√°cia de 0.99.
	* Sobre a classifica√ß√£o: baixa precis√£o para a classe 1, onde apenas 30% dos dados classificados como fraude realmente a s√£o.
	* Recall com bom desempenho, onde o modelo √© capaz de identificar 85% dos verdadeiros positivos.
	* F1-Score: m√©dia entre precision e recall de 0.45.

* O modelo **Gradient Boosting Otimizado** apresenta uma maior quantidade de acertos na classe de verdadeiros positivos (`recall = 0.84`).
	* No entanto, pode ser √∫til investigar maneiras de melhorar a precis√£o (`precision = 0.45`) sem sacrificar muito o recall, para reduzir o n√∫mero de transa√ß√µes leg√≠timas classificadas erroneamente como fraudulentas.

 * Conclu√≠mos que, dentro dos modelos trabalhados aqui, o **Decision Tree apresentou o melhor desempenho para o nosso conjunto de dados**.

**Pontos a serem melhorados:**

* Para classifica√ß√£o dos dados: utilizar t√©cnicas para lidar com a falta de balanceamento dos data sets (resampling, por exemplo).
* Utilizar as mesmas features para os diferentes modelos de forma a gerar compara√ß√µes mais fidedignas.
* Adicionar outras m√©tricas de compara√ß√£o, como a pr√≥pria curva ROC.

## üíª Principais linguagens
- Python
  - Pandas
  - Numpy
  - Seaborn
  - Plotly
  - Matplotlib
  - Scipy
  - Sklearn
  - Imblearn
  - Lightgbm
  - Joblib

## üë®‚Äçüíª Execu√ß√£o
Para executar os notebooks localmente, certifique-se de:

* Fazer o download dos arquivos `fraudTrain.csv` e `fraudTest.csv` [neste link do Kaggle](https://www.kaggle.com/datasets/kartik2112/fraud-detection) (eles s√£o muito grandes para serem colocados neste reposit√≥rio).
* Alterar o caminho nas linhas de c√≥digo que l√™em os data sets: `df_train = pd.read_csv("caminho/fraudTrain.csv")` e `df_test = pd.read_csv("caminho/fraudTest.csv")`.

Neste reposit√≥rio, voc√™ encontra 4 notebooks diferentes, cada um focado em um dos modelos (KNN, Decision Tree, Random Forest e Gradient Boosting).

###### Tags: `python` `data-science` `random-forest` `credit-card` `knn` `decision-tree` `fraud-detection` `gradient-boosting`
